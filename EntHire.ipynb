{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EntHire.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZTCjyOKwJGU",
        "outputId": "a83bf7db-6c63-4ab1-f197-77b684466562"
      },
      "source": [
        "!pip install colabcode\n",
        "!pip install fastapi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: colabcode in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: uvicorn==0.13.1 in /usr/local/lib/python3.7/dist-packages (from colabcode) (0.13.1)\n",
            "Requirement already satisfied: jupyterlab==3.0.7 in /usr/local/lib/python3.7/dist-packages (from colabcode) (3.0.7)\n",
            "Requirement already satisfied: pyngrok>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from colabcode) (5.0.5)\n",
            "Requirement already satisfied: nest-asyncio==1.4.3 in /usr/local/lib/python3.7/dist-packages (from colabcode) (1.4.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (4.7.1)\n",
            "Requirement already satisfied: tornado>=6.1.0 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (6.1)\n",
            "Requirement already satisfied: jupyterlab-server~=2.0 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (2.6.1)\n",
            "Requirement already satisfied: jupyter-server~=1.2 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (1.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (21.0)\n",
            "Requirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (2.11.3)\n",
            "Requirement already satisfied: nbclassic~=0.2 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (0.3.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (5.5.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (3.7.4.3)\n",
            "Requirement already satisfied: click==7.* in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10->jupyterlab==3.0.7->colabcode) (2.0.1)\n",
            "Requirement already satisfied: jupyter-client>=6.1.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (6.1.12)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.10.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.2.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (20.1.0)\n",
            "Requirement already satisfied: requests-unixsocket in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.2.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.11.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.0.5)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.7.1)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (3.3.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (22.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.6.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.1.3)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.1.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.1->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.8.1)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.2.0)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.23.0)\n",
            "Requirement already satisfied: json5 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.9.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (57.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (4.6.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (1.15.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (21.2.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.18.0)\n",
            "Requirement already satisfied: notebook<7 in /usr/local/lib/python3.7/dist-packages (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (4.10.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok>=5.0.0->colabcode) (3.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.3->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.0->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.20)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2018.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.5.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyterlab==3.0.7->colabcode) (0.2.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.4.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (3.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.5.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->jupyterlab==3.0.7->colabcode) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2021.5.30)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (0.67.0)\n",
            "Requirement already satisfied: starlette==0.14.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (0.14.2)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ak2q0f4TBMA"
      },
      "source": [
        "#importing the required libraries & packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import argparse\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import regexp_tokenize\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from sklearn.utils import shuffle\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia9vNfhWTZ8Z"
      },
      "source": [
        "data_frame = pd.read_csv(\"/content/drive/MyDrive/airline_sentiment_analysis.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "cDh_TsBITr06",
        "outputId": "992607b2-5fd4-4143-c79c-62950983abd6"
      },
      "source": [
        "data_frame.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                               text\n",
              "0           1  ...  @VirginAmerica plus you've added commercials t...\n",
              "1           3  ...  @VirginAmerica it's really aggressive to blast...\n",
              "2           4  ...  @VirginAmerica and it's a really big bad thing...\n",
              "3           5  ...  @VirginAmerica seriously would pay $30 a fligh...\n",
              "4           6  ...  @VirginAmerica yes, nearly every time I fly VX...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "FC8YZLt3TzG1",
        "outputId": "ef5ff359-3990-4717-cad0-eb6dbfdcbaf0"
      },
      "source": [
        "data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)\n",
        "data_frame.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                               text\n",
              "0          positive  @VirginAmerica plus you've added commercials t...\n",
              "1          negative  @VirginAmerica it's really aggressive to blast...\n",
              "2          negative  @VirginAmerica and it's a really big bad thing...\n",
              "3          negative  @VirginAmerica seriously would pay $30 a fligh...\n",
              "4          positive  @VirginAmerica yes, nearly every time I fly VX..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "9IiYNfqbYGJ1",
        "outputId": "8969afde-6c05-4f92-9674-aa753737d9b6"
      },
      "source": [
        "data_frame.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                               text\n",
              "0          positive  @VirginAmerica plus you've added commercials t...\n",
              "1          negative  @VirginAmerica it's really aggressive to blast...\n",
              "2          negative  @VirginAmerica and it's a really big bad thing...\n",
              "3          negative  @VirginAmerica seriously would pay $30 a fligh...\n",
              "4          positive  @VirginAmerica yes, nearly every time I fly VX..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "jfCwXjchgL2d",
        "outputId": "e273bfd4-3260-43af-c115-6f9ee1b9eeba"
      },
      "source": [
        "data_frame = shuffle(data_frame,random_state = 42)\n",
        "data_frame.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9193</th>\n",
              "      <td>negative</td>\n",
              "      <td>@USAirways They charged me for a flight they C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6112</th>\n",
              "      <td>positive</td>\n",
              "      <td>@JetBlue great flight! Great view! :-) http://...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>967</th>\n",
              "      <td>negative</td>\n",
              "      <td>@united they're not, actually. gate agent was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11279</th>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir No worries they called back 4 hrs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3061</th>\n",
              "      <td>positive</td>\n",
              "      <td>@united thank you. There was one here a few mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      airline_sentiment                                               text\n",
              "9193           negative  @USAirways They charged me for a flight they C...\n",
              "6112           positive  @JetBlue great flight! Great view! :-) http://...\n",
              "967            negative  @united they're not, actually. gate agent was ...\n",
              "11279          negative  @AmericanAir No worries they called back 4 hrs...\n",
              "3061           positive  @united thank you. There was one here a few mo..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "2hObaP05ge4s",
        "outputId": "f46e9872-3692-4055-a9b7-f11aad5ea021"
      },
      "source": [
        "data_frame = data_frame.reset_index()\n",
        "data_frame.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9193</td>\n",
              "      <td>negative</td>\n",
              "      <td>@USAirways They charged me for a flight they C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6112</td>\n",
              "      <td>positive</td>\n",
              "      <td>@JetBlue great flight! Great view! :-) http://...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>967</td>\n",
              "      <td>negative</td>\n",
              "      <td>@united they're not, actually. gate agent was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11279</td>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir No worries they called back 4 hrs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3061</td>\n",
              "      <td>positive</td>\n",
              "      <td>@united thank you. There was one here a few mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index airline_sentiment                                               text\n",
              "0   9193          negative  @USAirways They charged me for a flight they C...\n",
              "1   6112          positive  @JetBlue great flight! Great view! :-) http://...\n",
              "2    967          negative  @united they're not, actually. gate agent was ...\n",
              "3  11279          negative  @AmericanAir No worries they called back 4 hrs...\n",
              "4   3061          positive  @united thank you. There was one here a few mo..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "LQLZBSu_gmQe",
        "outputId": "bab8bd96-fad8-44d4-b4cc-f399458b12ef"
      },
      "source": [
        "data_frame = data_frame.drop(['index'],axis = 1)\n",
        "data_frame.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>@USAirways They charged me for a flight they C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@JetBlue great flight! Great view! :-) http://...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>@united they're not, actually. gate agent was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir No worries they called back 4 hrs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>@united thank you. There was one here a few mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                               text\n",
              "0          negative  @USAirways They charged me for a flight they C...\n",
              "1          positive  @JetBlue great flight! Great view! :-) http://...\n",
              "2          negative  @united they're not, actually. gate agent was ...\n",
              "3          negative  @AmericanAir No worries they called back 4 hrs...\n",
              "4          positive  @united thank you. There was one here a few mo..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8J1ns5Ogu5d",
        "outputId": "88922e78-27d6-4d3d-983f-d59d8439baf6"
      },
      "source": [
        "data_frame.info()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11541 entries, 0 to 11540\n",
            "Data columns (total 2 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   airline_sentiment  11541 non-null  object\n",
            " 1   text               11541 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 180.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VeolMPtg50Q",
        "outputId": "5ee4aefe-8411-4964-c315-ed7dc1bd0c13"
      },
      "source": [
        "data_frame['airline_sentiment'].unique()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative', 'positive'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOdwW2oChBBr",
        "outputId": "67b5b655-ee34-4c40-a981-93b54d59f72f"
      },
      "source": [
        "data_frame['airline_sentiment'].describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count        11541\n",
              "unique           2\n",
              "top       negative\n",
              "freq          9178\n",
              "Name: airline_sentiment, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "sgbRB6JXhJpO",
        "outputId": "8efdd7b0-5a4c-4835-aaa5-79a23b321e00"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_frame['airline_sentiment'].value_counts().plot.bar()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnWfUtMyjhlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96cfc79-aa1c-46f9-c84e-3e106fc7cc70"
      },
      "source": [
        "#repalcing the categorical values of 'airline_sentiment' to numeric values\n",
        "data_frame['airline_sentiment'].replace(('positive', 'negative'), (1, 0), inplace=True)\n",
        "data_frame['airline_sentiment'].value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    9178\n",
              "1    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx5SySKo_kvo"
      },
      "source": [
        "#forming the feature & label variables\n",
        "data = data_frame['text'].values.tolist()\n",
        "labels = data_frame['airline_sentiment'].values.tolist()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdA8JQ8_jhlQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310d2ef6-f76c-49b8-af72-6612b6eb635f"
      },
      "source": [
        "#First five samples text\n",
        "data[:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@USAirways They charged me for a flight they Cancelled Flightled, unbelievable and unheard of',\n",
              " '@JetBlue great flight! Great view! :-) http://t.co/Yxn00pnOav',\n",
              " \"@united they're not, actually. gate agent was so rude. now standing in a line waiting for reFlight Booking Problems. missed the only flight to STI. awful.\",\n",
              " \"@AmericanAir No worries they called back 4 hrs Late Flightr while I was asleep and took an additional $200 fee. So by AA standards everything's gr8\",\n",
              " \"@united thank you. There was one here a few months ago, but none now. Weird you don't have a club in one of the busiest airports in the US.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqhUtE4f_hAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f57ec2-4e22-4b2a-e859-5ec3412d8cd1"
      },
      "source": [
        "#first 5 samples label\n",
        "labels[:5]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 0, 0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pduz91hcjhlb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d4e6d14-003c-4796-9431-18006204a877"
      },
      "source": [
        "#splitting the data into 80 and 20 split\n",
        "train_X, test_X, y_train, y_test = train_test_split(data, labels, test_size=0.2, \n",
        "                                                    random_state=42, shuffle=True)\n",
        "\n",
        "print(f'Number of training examples: {len(train_X)}')\n",
        "print(f'Number of testing examples: {len(test_X)}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 9232\n",
            "Number of testing examples: 2309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_20Lfoqjhll"
      },
      "source": [
        "**Text Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGX16pKBjhlm"
      },
      "source": [
        "# Here is a default pattern for tokenization\n",
        "default_pattern =  r\"\"\"(?x)                  \n",
        "                        (?:[A-Z]\\.)+          \n",
        "                        |\\$?\\d+(?:\\.\\d+)?%?    \n",
        "                        |\\w+(?:[-']\\w+)*      \n",
        "                        |\\.\\.\\.               \n",
        "                        |(?:[.,;\"'?():-_`])    \n",
        "                    \"\"\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkncRcuijhlx"
      },
      "source": [
        "#funtion for tokenizing the data\n",
        "def tokenize(text, pattern = default_pattern):\n",
        "  text = text.lower()\n",
        "  return regexp_tokenize(text, pattern)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCTB0sWwjhl7"
      },
      "source": [
        "# Tokenize training text into tokens\n",
        "tokenized_text = []\n",
        "for i in range(0, len(train_X)):\n",
        "    tokenized_text.append(tokenize(train_X[i]))\n",
        "\n",
        "X_train = tokenized_text\n",
        "\n",
        "# Tokenize testing text into tokens\n",
        "tokenized_text = []\n",
        "for i in range(0, len(test_X)):\n",
        "    tokenized_text.append(tokenize(test_X[i]))\n",
        "\n",
        "X_test = tokenized_text"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7yG2O98jhmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc907f7-85d9-471d-a580-2177341b376c"
      },
      "source": [
        "#tokenized train & test data\n",
        "print(X_train[0], X_train[1])\n",
        "print(X_test[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['@', 'usairways', 'been', 'on', 'hold', '2.5', 'hours', 'now', 'system', 'hung', 'up', 'on', 'me', 'twice', 'after', 'an', 'hour', 'holding', '.', ':', '(', 'trying', '2', 'correct', 'online', 'flight', 'booking', 'problems', 'error', '.', 'unhappy'] ['@', 'americanair', 'what', 'is', 'that', '?', 'why', 'even', 'bother', 'catering', 'dog', 'food', 'that', 'no', 'one', 'will', 'eat', '?', 'http', ':', 't', '.', 'co', 'ifespcbztm']\n",
            "['@', 'americanair', 'can', 'you', 'tell', 'me', 'why', 'all', 'flights', 'from', 'xna', '2', 'dfw', 'are', 'cancelled', 'flightled', 'for', 'tomorrow', 'morning', 'already', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFyEv5ERPuB3"
      },
      "source": [
        "#building dictionary\n",
        "def createDictionary(data):\n",
        "  dictionary = dict()\n",
        "  for sample in  data:\n",
        "    for token in sample:\n",
        "      dictionary[token] = dictionary.get(token, 0) + 1\n",
        "  #sorting the dictionary based on the values\n",
        "  sorted_dict = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
        "  return dict(sorted_dict)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgbUxDeAU4oR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e713026f-2851-4b34-91d0-5c293765b793"
      },
      "source": [
        "bog = createDictionary(X_train)\n",
        "#top 10 items in the dictionary\n",
        "print(\"Top 10 tokens in the training dictionary:\\n\")\n",
        "list(bog.items())[:10]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 tokens in the training dictionary:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', 10616),\n",
              " ('@', 10369),\n",
              " ('to', 5633),\n",
              " ('the', 4027),\n",
              " ('i', 3425),\n",
              " ('a', 2967),\n",
              " (',', 2837),\n",
              " ('united', 2734),\n",
              " ('you', 2721),\n",
              " ('for', 2719)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "auz1uD0IjhmI"
      },
      "source": [
        "#Navie Bayes Classifier \n",
        "class NBClassifier:\n",
        "\n",
        "    def __init__(self, X_train, y_train, size):\n",
        "      self.X_train = X_train\n",
        "      self.y_train = y_train\n",
        "      self.size = size\n",
        "\n",
        "    def createDictionary(self):\n",
        "      \"\"\" Function: To create a dictionary of tokens\"\"\"\n",
        "      dictionary = dict()\n",
        "      for sample in  X_train:\n",
        "        for token in sample:\n",
        "          dictionary[token] = dictionary.get(token, 0) + 1\n",
        "      #sorting the dictionary based on the values\n",
        "      sorted_dict = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
        "      return dict(sorted_dict)\n",
        "    \n",
        "    def fit(self):\n",
        "      \"\"\" Function: To compute the count of words in training data dictionary\"\"\"\n",
        "      \n",
        "      X_train_dict = self.createDictionary()\n",
        "      if self.size == 'full':\n",
        "        self.words_list = list(X_train_dict.keys())\n",
        "        self.words_count = dict.fromkeys(self.words_list, None)\n",
        "      else:\n",
        "        self.words_list = list(X_train_dict.keys())[:int(self.size)]\n",
        "        self.words_count = dict.fromkeys(self.words_list, None)\n",
        "            \n",
        "      #DataFrame of training data\n",
        "      train = pd.DataFrame(columns = ['X_train', 'y_train'])\n",
        "      train['X_train'] = X_train\n",
        "      train['y_train'] = y_train\n",
        "\n",
        "      train_0 = train.copy()[train['y_train'] == 0]\n",
        "      train_1 = train.copy()[train['y_train'] == 1]\n",
        "      train_2 = train.copy()[train['y_train'] == 2]\n",
        "\n",
        "      #computing the prior of each class\n",
        "      Pr0 = train_0.shape[0]/train.shape[0]\n",
        "      Pr1 = train_1.shape[0]/train.shape[0]\n",
        "      Pr2 = train_2.shape[0]/train.shape[0]\n",
        "      \n",
        "      self.Prior = np.array([Pr0, Pr1, Pr2])\n",
        "        \n",
        "      #converting list of lists into a list\n",
        "      def flatList(listOfList):\n",
        "        flatten = []\n",
        "        for elem in listOfList:\n",
        "          flatten.extend(elem)\n",
        "        return flatten\n",
        "  \n",
        "      #Creating the data list for each class - tokens of each class\n",
        "      X_train_0 = flatList(train[train['y_train'] == 0]['X_train'].tolist())\n",
        "      X_train_1 = flatList(train[train['y_train'] == 1]['X_train'].tolist())\n",
        "      X_train_2 = flatList(train[train['y_train'] == 2]['X_train'].tolist())\n",
        "    \n",
        "      self.X_train_len = np.array([len(X_train_0), len(X_train_1), len(X_train_2)])\n",
        "\n",
        "      for token in self.words_list:\n",
        "        #list to store three word counts of a token\n",
        "        res = []\n",
        "\n",
        "        #inserting count of token in class 0: Neutral\n",
        "        res.insert(0, X_train_0.count(token))\n",
        "\n",
        "        #inserting count of token in class 1: Positive\n",
        "        res.insert(1, X_train_1.count(token))\n",
        "\n",
        "          #inserting count of token in class 2: Negative\n",
        "        res.insert(2, X_train_2.count(token))\n",
        "\n",
        "        #assigning the count list to its token in the dictionary \n",
        "        self.words_count[token] = res\n",
        "      return self\n",
        "\n",
        "    def predict(self, X_test):\n",
        "      \"\"\" Function: Predicts the label of the data\"\"\"     \n",
        "      pred = []\n",
        "      for sample in X_test:\n",
        "        mul = np.array([1,1,1])\n",
        "        for tokens in sample:\n",
        "          vocab_count = len(self.words_list)\n",
        "          if tokens in self.words_list:\n",
        "            prob = ((np.array(self.words_count[tokens])+1) / (self.X_train_len + vocab_count))\n",
        "          #except:\n",
        "            #prob = ((np.array([0,0,0])+1) / (self.X_train_len + vocab_count))\n",
        "          mul = mul * prob\n",
        "        val = mul * self.Prior\n",
        "        pred.append(np.argmax(val))\n",
        "      return pred\n",
        "    \n",
        "    def score(self, pred, labels):\n",
        "      \"\"\" Function: To compute the perfoemance of the model\"\"\"\n",
        "      correct = (np.array(pred) == np.array(labels)).sum()\n",
        "      accuracy = correct/len(pred)\n",
        "      return correct, accuracy"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYOgoiHUchMA"
      },
      "source": [
        "# Creating holders to store the model performance results\n",
        "attributes = []\n",
        "corr = []\n",
        "acc = []\n",
        "\n",
        "#function to call for storing the results\n",
        "def storeResults(attr, cor,ac):\n",
        "  attributes.append(attr)\n",
        "  corr.append(round(cor, 3))\n",
        "  acc.append(round(ac, 3))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0TqGF2sjhmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64205c75-016c-4ba2-9e17-e5a17c5e6b65"
      },
      "source": [
        "#training the classifier     \n",
        "nb = NBClassifier(X_train, y_train, 'full')  \n",
        "nb.fit()\n",
        "\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NBClassifier Model miss any prediction??? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLDjMGp0jhmR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06921abc-0853-4cf8-8461-30166a6b1086"
      },
      "source": [
        "#Performance of the classifier\n",
        "cor1, acc1 = nb.score(y_pred, y_test)\n",
        "print(\"Count of Correct Predictions:\", cor1)\n",
        "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor1, len(y_pred), acc1))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Correct Predictions: 2108\n",
            "Accuracy of the model: 2108 / 2309 = 0.9129 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtmKoVJnc5fB"
      },
      "source": [
        "storeResults('Unprocessed Data', cor1, acc1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBLcYlOlqI7v"
      },
      "source": [
        "**Further Processing Text Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIOaYPc_jhmW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed75f116-97ee-4b27-f801-aef77ee6a5af"
      },
      "source": [
        "#string of punctiations\n",
        "string.punctuation"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "45mxN-D2jhma"
      },
      "source": [
        "#Removing the punctuation\n",
        "def removePunctuation(data):\n",
        "    update = []\n",
        "    for sample in data:\n",
        "        #removing punctuation from the tokens\n",
        "        re_punct = [''.join(char for char in word if char not in string.punctuation) for word in sample]\n",
        "        #removes the empty strings\n",
        "        re_punct = [word for word in re_punct if word]\n",
        "       \n",
        "        update.append(re_punct)\n",
        "    return update"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB3wla2tFLWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "550760fc-bd1d-4a52-e948-2240e1151384"
      },
      "source": [
        "#Removing punctuation from training data text tokens  \n",
        "X_train_P = removePunctuation(X_train)\n",
        "\n",
        "#Removing punctuation from testing data text tokens\n",
        "X_test_P = removePunctuation(X_test)\n",
        "\n",
        "#train & test data after removing punctuation\n",
        "print(X_train_P[0])\n",
        "print(X_test_P[0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['usairways', 'been', 'on', 'hold', '25', 'hours', 'now', 'system', 'hung', 'up', 'on', 'me', 'twice', 'after', 'an', 'hour', 'holding', 'trying', '2', 'correct', 'online', 'flight', 'booking', 'problems', 'error', 'unhappy']\n",
            "['americanair', 'can', 'you', 'tell', 'me', 'why', 'all', 'flights', 'from', 'xna', '2', 'dfw', 'are', 'cancelled', 'flightled', 'for', 'tomorrow', 'morning', 'already']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLWE_rUUjhmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4e5c91-fb4b-4048-af97-538fc27ddfe4"
      },
      "source": [
        "#training the classifier     \n",
        "nb_punct = NBClassifier(X_train_P, y_train, 'full')\n",
        "nb_punct.fit()\n",
        "\n",
        "y_pred_P = nb_punct.predict(X_test_P)\n",
        "\n",
        "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_P))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NBClassifier Model miss any prediction??? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PC7OsxL7Qyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb3d9593-0b88-42b2-a064-b9b1f39a907e"
      },
      "source": [
        "#Performance of the classifier\n",
        "cor2, acc2 = nb_punct.score(y_pred_P, y_test)\n",
        "print(\"Count of Correct Predictions:\", cor2)\n",
        "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor2, len(y_pred_P), acc2))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Correct Predictions: 2104\n",
            "Accuracy of the model: 2104 / 2309 = 0.9112 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nGvM61Odq_C"
      },
      "source": [
        "storeResults('No Punctuation Data', cor2, acc2)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmTW-U4iFHFQ"
      },
      "source": [
        "def removeStopWords(data):\n",
        "    update = []\n",
        "    stopwords = ['the', 'at','i', 'of', 'us', 'have', 'a', 'you','ours', 'themselves', \n",
        "                 'that', 'this', 'be', 'is', 'for']\n",
        "    for sample in data:\n",
        "        #removing stopwords from tokenized data\n",
        "        re_stop = [word for word in sample if word not in stopwords]\n",
        "        \n",
        "        update.append(re_stop)\n",
        "    return update"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZZzVzpmjhmd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddff9b3f-49fc-4b01-c09e-105643d69394"
      },
      "source": [
        "#Removing stopwords from training data text tokens  \n",
        "X_train_S = removeStopWords(X_train)\n",
        "\n",
        "#Removing stopwords from testing data text tokens\n",
        "X_test_S = removeStopWords(X_test)\n",
        "\n",
        "#train & test data after removing stopwords\n",
        "print(X_train_S[0])\n",
        "print(X_test_S[0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['@', 'usairways', 'been', 'on', 'hold', '2.5', 'hours', 'now', 'system', 'hung', 'up', 'on', 'me', 'twice', 'after', 'an', 'hour', 'holding', '.', ':', '(', 'trying', '2', 'correct', 'online', 'flight', 'booking', 'problems', 'error', '.', 'unhappy']\n",
            "['@', 'americanair', 'can', 'tell', 'me', 'why', 'all', 'flights', 'from', 'xna', '2', 'dfw', 'are', 'cancelled', 'flightled', 'tomorrow', 'morning', 'already', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYzud_H1FHQX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5dd46ef-29e9-4bcb-c3c5-d71e46928d9d"
      },
      "source": [
        "#training the classifier     \n",
        "nb_stop = NBClassifier(X_train_S, y_train, 'full')\n",
        "nb_stop.fit()\n",
        "\n",
        "y_pred_S = nb_stop.predict(X_test_S)\n",
        "\n",
        "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_S))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NBClassifier Model miss any prediction??? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avvjr8QGjhmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cadc97cc-63e8-4be6-c6f9-1dd770e20a29"
      },
      "source": [
        "#Performance of the classifier\n",
        "cor3, acc3 = nb_stop.score(y_pred_S, y_test)\n",
        "print(\"Count of Correct Predictions:\", cor3)\n",
        "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor3, len(y_pred_S), acc3))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Correct Predictions: 2116\n",
            "Accuracy of the model: 2116 / 2309 = 0.9164 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deKrYJxEelgD"
      },
      "source": [
        "storeResults('Removed few Stopwords', cor3, acc3)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0o0VhYRJFt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f79a45f-4644-4eaf-a095-c1b1b0e878e3"
      },
      "source": [
        "#Removing stopwords from training data text tokens  \n",
        "X_train_PS = removeStopWords(X_train_P)\n",
        "\n",
        "#Removing stopwords from testing data text tokens\n",
        "X_test_PS = removeStopWords(X_test_P)\n",
        "\n",
        "#train & test data after removing stopwords\n",
        "print(X_train_PS[0])\n",
        "print(X_test_PS[0])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['usairways', 'been', 'on', 'hold', '25', 'hours', 'now', 'system', 'hung', 'up', 'on', 'me', 'twice', 'after', 'an', 'hour', 'holding', 'trying', '2', 'correct', 'online', 'flight', 'booking', 'problems', 'error', 'unhappy']\n",
            "['americanair', 'can', 'tell', 'me', 'why', 'all', 'flights', 'from', 'xna', '2', 'dfw', 'are', 'cancelled', 'flightled', 'tomorrow', 'morning', 'already']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4tzU0AlJFuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67a26da-1ddf-4997-dfb8-ab74c51de1bb"
      },
      "source": [
        "#training the classifier     \n",
        "nb_PS = NBClassifier(X_train_PS, y_train, 'full')\n",
        "nb_PS.fit()\n",
        "\n",
        "y_pred_PS = nb_PS.predict(X_test_PS)\n",
        "\n",
        "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_PS))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NBClassifier Model miss any prediction??? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJHLQjGkJFuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc9fcd4e-9328-4f93-89fb-56e4ab1ceb2f"
      },
      "source": [
        "#Performance of the classifier\n",
        "cor4, acc4 = nb_PS.score(y_pred_PS, y_test)\n",
        "print(\"Count of Correct Predictions:\", cor4)\n",
        "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor4, len(y_pred_PS), acc4))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Correct Predictions: 2102\n",
            "Accuracy of the model: 2102 / 2309 = 0.9104 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmX0dPEjucaA"
      },
      "source": [
        "storeResults('Removed both Punctuation & Few Stopwords', cor4, acc4)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07HMC5cgXhbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf03637-db5b-4d6b-8d32-184af6a44980"
      },
      "source": [
        "#total tokens in training dictionary\n",
        "print('Total tokens in the dictionary:', len(bog))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total tokens in the dictionary: 11400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyM2TaO1Ugf9"
      },
      "source": [
        "**Considering Top 5k Tokens**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5RLPdY2XfYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "861a9802-620f-481e-ef1a-51a6c270fc40"
      },
      "source": [
        "#training the classifier - 5000 tokens \n",
        "nb_5k = NBClassifier(X_train, y_train, '5000')\n",
        "nb_5k.fit()\n",
        "\n",
        "y_pred_5k = nb_5k.predict(X_test)\n",
        "\n",
        "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_5k))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NBClassifier Model miss any prediction??? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-D-QQcOXfYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0aba2bb-f2c3-4bd0-b056-f36f7bdeba0e"
      },
      "source": [
        "#Performance of the classifier\n",
        "cor5, acc5 = nb_5k.score(y_pred_5k, y_test)\n",
        "print(\"Count of Correct Predictions:\", cor5)\n",
        "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor5, len(y_pred), acc5))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Correct Predictions: 2111\n",
            "Accuracy of the model: 2111 / 2309 = 0.9142 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZXLE0czuu9k"
      },
      "source": [
        "storeResults('5k Tokens of Voab - Unprocessed Data', cor5, acc5)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq3t4Q8FboU4"
      },
      "source": [
        "**5k Tokens of Vocabulary - No Punctuation Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAtviJUjboU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86bf38a0-fe5b-4798-99fb-1203c3eff8a4"
      },
      "source": [
        "#training the classifier - 5000 tokens \n",
        "nb_5k_P = NBClassifier(X_train_P, y_train, '5000')\n",
        "nb_5k_P.fit()\n",
        "\n",
        "y_pred_5k_P = nb_5k_P.predict(X_test_P)\n",
        "\n",
        "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_5k_P))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NBClassifier Model miss any prediction??? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaaWsEiGboVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6ee34e-caec-4249-dd1a-d089dfe71bac"
      },
      "source": [
        "#Performance of the classifier\n",
        "cor6, acc6 = nb_5k.score(y_pred_5k_P, y_test)\n",
        "print(\"Count of Correct Predictions:\", cor6)\n",
        "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor6, len(y_pred), acc6))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Correct Predictions: 2104\n",
            "Accuracy of the model: 2104 / 2309 = 0.9112 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTvnor0fj9s8"
      },
      "source": [
        "storeResults('5k Tokens of Voab - No Punctuation Data', cor6, acc6)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXHL1dEOb4X7"
      },
      "source": [
        "**5k Tokens of Vocabulary - Removed few Stopwords**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U51l64Ob4X8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d085a1c1-79bf-40cc-f511-80563383b5d2"
      },
      "source": [
        "#training the classifier - 5000 tokens \n",
        "nb_5k_S = NBClassifier(X_train_S, y_train, '5000')\n",
        "nb_5k_S.fit()\n",
        "\n",
        "y_pred_5k_S = nb_5k_S.predict(X_test_S)\n",
        "\n",
        "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_5k_S))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NBClassifier Model miss any prediction??? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wKG4XjHb4YA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a4482f-c367-4df1-978a-9bd36bacc5fd"
      },
      "source": [
        "#Performance of the classifier\n",
        "cor7, acc7 = nb_5k_S.score(y_pred_5k_S, y_test)\n",
        "print(\"Count of Correct Predictions:\", cor7)\n",
        "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor7, len(y_pred), acc7))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Correct Predictions: 2121\n",
            "Accuracy of the model: 2121 / 2309 = 0.9186 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGMbP2XykOut"
      },
      "source": [
        "storeResults('5k Tokens of Voab - Removed few Stopwords', cor7, acc7)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlJ6bkSVpqTp"
      },
      "source": [
        "**5k Tokens of Vocabulary - Removed both Punctuation & Few Stopwords**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpRG7dI0pqTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f691a1-6465-406c-b44a-53c880589df3"
      },
      "source": [
        "#training the classifier - 5000 tokens \n",
        "nb_5k_PS = NBClassifier(X_train_PS, y_train, '5000')\n",
        "nb_5k_PS.fit()\n",
        "\n",
        "y_pred_5k_PS = nb_5k_PS.predict(X_test_PS)\n",
        "\n",
        "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_5k_PS))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NBClassifier Model miss any prediction??? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fmSSEzdpqT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7964a1-2967-4aac-80be-2ddb6ef3c516"
      },
      "source": [
        "#Performance of the classifier\n",
        "cor8, acc8 = nb_5k_PS.score(y_pred_5k_PS, y_test)\n",
        "print(\"Count of Correct Predictions:\", cor8)\n",
        "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor8, len(y_pred), acc8))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Correct Predictions: 2112\n",
            "Accuracy of the model: 2112 / 2309 = 0.9147 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgXuV2wHpqUE"
      },
      "source": [
        "storeResults('5k Tokens of Voab - Removed both Punctuation & Few Stopwords', cor8, acc8)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cxUwo_mvLVZ"
      },
      "source": [
        "**Considering Top 10k Tokens**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW1tBdcQvLVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41b228c-2ef0-4ef9-c6b5-b8e6b950ae87"
      },
      "source": [
        "#training the classifier - 5000 tokens \n",
        "nb_10k = NBClassifier(X_train, y_train, '5000')\n",
        "nb_10k.fit()\n",
        "\n",
        "y_pred_10k = nb_10k.predict(X_test)\n",
        "\n",
        "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_10k))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NBClassifier Model miss any prediction??? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqgZMo7MvLVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7531185a-fcca-4059-fc8b-0c4609183e71"
      },
      "source": [
        "#Performance of the classifier\n",
        "cor9, acc9 = nb_10k.score(y_pred_10k, y_test)\n",
        "print(\"Count of Correct Predictions:\", cor9)\n",
        "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor9, len(y_pred), acc9))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Correct Predictions: 2111\n",
            "Accuracy of the model: 2111 / 2309 = 0.9142 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBALRXZsvLV0"
      },
      "source": [
        "storeResults('10k Tokens of Voab - Unprocessed Data', cor9, acc9)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIRzN1PmvLV7"
      },
      "source": [
        "**10k Tokens of Vocabulary - No Punctuation Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UCyGLm-vLV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100305cf-36dc-4007-a784-b2bc9dc53093"
      },
      "source": [
        "#training the classifier - 10000 tokens \n",
        "nb_10k_P = NBClassifier(X_train_P, y_train, '10000')\n",
        "nb_10k_P.fit()\n",
        "\n",
        "y_pred_10k_P = nb_10k_P.predict(X_test_P)\n",
        "  \n",
        "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred_10k_P))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NBClassifier Model miss any prediction??? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnsMkZ9DvLWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e2a3c7d-d750-47a6-e19c-8eb08998de98"
      },
      "source": [
        "#Performance of the classifier\n",
        "cor10, acc10 = nb_10k_P.score(y_pred_10k_P, y_test)\n",
        "print(\"Count of Correct Predictions:\", cor10)\n",
        "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor10, len(y_pred), acc10))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Correct Predictions: 2109\n",
            "Accuracy of the model: 2109 / 2309 = 0.9134 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln6eIsPzvLWN"
      },
      "source": [
        "storeResults('10k Tokens of Voab - No Punctuation Data', cor10, acc10)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe1e-hhxvLWT"
      },
      "source": [
        "**10k Tokens of Vocabulary - Removed few Stopwords**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOt5et-PvLWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ca9211-2602-4583-cfd7-6795e5ab1055"
      },
      "source": [
        "#training the classifier - 10000 tokens \n",
        "nb_10k_S = NBClassifier(X_train_S, y_train, '10000')\n",
        "nb_10k_S.fit()\n",
        "\n",
        "y_pred_10k_S = nb_10k_S.predict(X_test_S)\n",
        "  \n",
        "print(\"NBClassifier Model miss any Srediction???\", len(X_test) != len(y_pred_10k_S))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NBClassifier Model miss any Srediction??? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpYEMhzVvLWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534a8abf-911f-4846-8bff-9b3f9402d44c"
      },
      "source": [
        "#Performance of the classifier\n",
        "cor11, acc11 = nb_10k_S.score(y_pred_10k_S, y_test)\n",
        "print(\"Count of Correct Predictions:\", cor11)\n",
        "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor11, len(y_pred), acc11))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Correct Predictions: 2112\n",
            "Accuracy of the model: 2112 / 2309 = 0.9147 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBngQ4tLvLWf"
      },
      "source": [
        "storeResults('10k Tokens of Voab - Removed few Stopwords', cor11, acc11)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egUb3LyVvLWi"
      },
      "source": [
        "**10k Tokens of Vocabulary - Removed both Punctuation & Few Stopwords**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGR0Tu9FvLWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198cf853-b969-4e04-d2c6-7ac11b5d9004"
      },
      "source": [
        "#training the classifier - 10000 tokenPS \n",
        "nb_10k_PS = NBClassifier(X_train_PS, y_train, '10000')\n",
        "nb_10k_PS.fit()\n",
        "\n",
        "y_pred_10k_PS = nb_10k_PS.predict(X_test_PS)\n",
        "\n",
        "print(\"NBClaPSPSifier Model miSS any PSrediction???\", len(X_test) != len(y_pred_10k_PS))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NBClaPSPSifier Model miSS any PSrediction??? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjHTZzELvLWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e90cd11-4a5e-4064-e191-69ba0db12798"
      },
      "source": [
        "#Performance of the classifier\n",
        "cor12, acc12 = nb_10k_PS.score(y_pred_10k_PS, y_test)\n",
        "print(\"Count of Correct Predictions:\", cor12)\n",
        "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor12, len(y_pred), acc12))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Correct Predictions: 2102\n",
            "Accuracy of the model: 2102 / 2309 = 0.9104 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3oh7WgpvLWq"
      },
      "source": [
        "storeResults('10k Tokens of Voab - Removed both Punctuation & Few Stopwords', cor12, acc12)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgnjsl6mrRpI"
      },
      "source": [
        "### **10. Comparing the Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clKeFYmweE8E"
      },
      "source": [
        "results = pd.DataFrame({ 'Data Modification': attributes,    \n",
        "    'Correct Predictions': corr,\n",
        "    'Model Accuracy': acc})"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZIZL7WneE2v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "fb17c0cb-2407-4d66-9f60-77edf5b89ec8"
      },
      "source": [
        "results.sort_values(by=['Model Accuracy', 'Correct Predictions'], ascending=False)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data Modification</th>\n",
              "      <th>Correct Predictions</th>\n",
              "      <th>Model Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5k Tokens of Voab - Removed few Stopwords</td>\n",
              "      <td>2121</td>\n",
              "      <td>0.919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Removed few Stopwords</td>\n",
              "      <td>2116</td>\n",
              "      <td>0.916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5k Tokens of Voab - Removed both Punctuation &amp;...</td>\n",
              "      <td>2112</td>\n",
              "      <td>0.915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10k Tokens of Voab - Removed few Stopwords</td>\n",
              "      <td>2112</td>\n",
              "      <td>0.915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5k Tokens of Voab - Unprocessed Data</td>\n",
              "      <td>2111</td>\n",
              "      <td>0.914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10k Tokens of Voab - Unprocessed Data</td>\n",
              "      <td>2111</td>\n",
              "      <td>0.914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10k Tokens of Voab - No Punctuation Data</td>\n",
              "      <td>2109</td>\n",
              "      <td>0.913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Unprocessed Data</td>\n",
              "      <td>2108</td>\n",
              "      <td>0.913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No Punctuation Data</td>\n",
              "      <td>2104</td>\n",
              "      <td>0.911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5k Tokens of Voab - No Punctuation Data</td>\n",
              "      <td>2104</td>\n",
              "      <td>0.911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Removed both Punctuation &amp; Few Stopwords</td>\n",
              "      <td>2102</td>\n",
              "      <td>0.910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10k Tokens of Voab - Removed both Punctuation ...</td>\n",
              "      <td>2102</td>\n",
              "      <td>0.910</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Data Modification  ...  Model Accuracy\n",
              "6           5k Tokens of Voab - Removed few Stopwords  ...           0.919\n",
              "2                               Removed few Stopwords  ...           0.916\n",
              "7   5k Tokens of Voab - Removed both Punctuation &...  ...           0.915\n",
              "10         10k Tokens of Voab - Removed few Stopwords  ...           0.915\n",
              "4                5k Tokens of Voab - Unprocessed Data  ...           0.914\n",
              "8               10k Tokens of Voab - Unprocessed Data  ...           0.914\n",
              "9            10k Tokens of Voab - No Punctuation Data  ...           0.913\n",
              "0                                    Unprocessed Data  ...           0.913\n",
              "1                                 No Punctuation Data  ...           0.911\n",
              "5             5k Tokens of Voab - No Punctuation Data  ...           0.911\n",
              "3            Removed both Punctuation & Few Stopwords  ...           0.910\n",
              "11  10k Tokens of Voab - Removed both Punctuation ...  ...           0.910\n",
              "\n",
              "[12 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLZmvBhlmwKs"
      },
      "source": [
        ""
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLCkKM-KCA8B"
      },
      "source": [
        "**Developing API server using Fast API and Swagger UI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_jL2xEqzBqH"
      },
      "source": [
        "#Saving the model\n",
        "Pkl_Filename = \"Naive_Bayes.pkl\"  \n",
        "\n",
        "with open(Pkl_Filename, 'wb') as file:  \n",
        "    pickle.dump(nb, file)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyCYr5OA3OOX"
      },
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class Text(BaseModel):\n",
        "    english_text:list\n",
        "    \n",
        "    class Config:\n",
        "        schema_extra = {\n",
        "            \"example\": {\n",
        "                \"english_text\": [\"This is the worst flight for traveling\"]\n",
        "            }\n",
        "        }"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25jZXDp4zCvc"
      },
      "source": [
        "from fastapi import FastAPI\n",
        "import pickle\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_model():\n",
        "    global model\n",
        "    model = pickle.load(open(\"Naive_Bayes.pkl\", \"rb\"))\n",
        "\n",
        "@app.get('/')\n",
        "def index():\n",
        "    return {'message': 'This is the homepage of the API '}\n",
        "\n",
        "@app.post('/predict')\n",
        "def get_sentiment(data:Text):\n",
        "    received = data.dict()\n",
        "    text = received['english_text']\n",
        "    tokenized_text = []\n",
        "    for i in range(0, len(text)):\n",
        "        tokenized_text.append(tokenize(text[i]))\n",
        "    text = tokenized_text\n",
        "    text = removePunctuation(text)\n",
        "    text = removeStopWords(text)\n",
        "    \n",
        "    pred_category = model.predict(text)\n",
        "    if pred_category[0] == 1:\n",
        "      pred = \"positive\"\n",
        "    else:\n",
        "        pred = \"negative\"\n",
        "        \n",
        "    return {'prediction': pred}"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K10DRvhLzE0d"
      },
      "source": [
        "from colabcode import ColabCode\n",
        "server = ColabCode(port=10000, code=False)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7RMsUchzHEz"
      },
      "source": [
        "server.run_app(app=app)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYJVDkHhy0Fp",
        "outputId": "3f850ed0-ee46-4267-9c9c-df48ab803f31"
      },
      "source": [
        ""
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://71ee23c09626.ngrok.io\" -> \"http://localhost:10000\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}