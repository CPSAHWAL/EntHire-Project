{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EntHire.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TeNMeepfy7IR",
        "outputId": "4bb1fe21-29dc-48fd-9e62-86ec9397f315"
      },
      "source": [
        "!pip install colabcode\n",
        "!pip install fastapi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting colabcode\n",
            "  Downloading colabcode-0.3.0-py3-none-any.whl (5.0 kB)\n",
            "Collecting jupyterlab==3.0.7\n",
            "  Downloading jupyterlab-3.0.7-py3-none-any.whl (8.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 6.4 MB/s \n",
            "\u001b[?25hCollecting uvicorn==0.13.1\n",
            "  Downloading uvicorn-0.13.1-py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting nest-asyncio==1.4.3\n",
            "  Downloading nest_asyncio-1.4.3-py3-none-any.whl (5.3 kB)\n",
            "Collecting pyngrok>=5.0.0\n",
            "  Downloading pyngrok-5.0.5.tar.gz (745 kB)\n",
            "\u001b[K     |████████████████████████████████| 745 kB 61.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (21.0)\n",
            "Collecting jupyter-server~=1.2\n",
            "  Downloading jupyter_server-1.10.1-py3-none-any.whl (392 kB)\n",
            "\u001b[K     |████████████████████████████████| 392 kB 42.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (4.7.1)\n",
            "Collecting jupyterlab-server~=2.0\n",
            "  Downloading jupyterlab_server-2.6.1-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting nbclassic~=0.2\n",
            "  Downloading nbclassic-0.3.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (5.5.0)\n",
            "Requirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (2.11.3)\n",
            "Collecting tornado>=6.1.0\n",
            "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
            "\u001b[K     |████████████████████████████████| 428 kB 33.4 MB/s \n",
            "\u001b[?25hCollecting h11>=0.8\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (3.7.4.3)\n",
            "Requirement already satisfied: click==7.* in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10->jupyterlab==3.0.7->colabcode) (2.0.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.6.1)\n",
            "Collecting anyio<4,>=3.1.0\n",
            "  Downloading anyio-3.3.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.7.1)\n",
            "Collecting jupyter-client>=6.1.1\n",
            "  Downloading jupyter_client-6.1.12-py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 65.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.2.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (20.1.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.11.0)\n",
            "Collecting requests-unixsocket\n",
            "  Downloading requests_unixsocket-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (22.1.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.0.5)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.1.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.10.1)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.1->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.23.0)\n",
            "Collecting json5\n",
            "  Downloading json5-0.9.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.9.1)\n",
            "Collecting jsonschema>=3.0.1\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.18.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (21.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (57.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (4.6.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (1.15.0)\n",
            "Requirement already satisfied: notebook<7 in /usr/local/lib/python3.7/dist-packages (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (4.10.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok>=5.0.0->colabcode) (3.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.3->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.0->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.20)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2018.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.5.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyterlab==3.0.7->colabcode) (0.2.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (3.3.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.5.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.4.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.5.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->jupyterlab==3.0.7->colabcode) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2021.5.30)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.0.5-py3-none-any.whl size=19262 sha256=7af63826b2408fdd668bb3675f1dffa270d4a7304c81a36507ad2073d2224f93\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/f7/72/35c95a53d15b91dd00df6cf1304d49a31ec5ed6f954c2d4e32\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: tornado, jsonschema, sniffio, jupyter-client, websocket-client, requests-unixsocket, anyio, jupyter-server, json5, nbclassic, jupyterlab-server, h11, uvicorn, pyngrok, nest-asyncio, jupyterlab, colabcode\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 5.3.5\n",
            "    Uninstalling jupyter-client-5.3.5:\n",
            "      Successfully uninstalled jupyter-client-5.3.5\n",
            "  Attempting uninstall: nest-asyncio\n",
            "    Found existing installation: nest-asyncio 1.5.1\n",
            "    Uninstalling nest-asyncio-1.5.1:\n",
            "      Successfully uninstalled nest-asyncio-1.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\u001b[0m\n",
            "Successfully installed anyio-3.3.0 colabcode-0.3.0 h11-0.12.0 json5-0.9.6 jsonschema-3.2.0 jupyter-client-6.1.12 jupyter-server-1.10.1 jupyterlab-3.0.7 jupyterlab-server-2.6.1 nbclassic-0.3.1 nest-asyncio-1.4.3 pyngrok-5.0.5 requests-unixsocket-0.2.0 sniffio-1.2.0 tornado-6.1 uvicorn-0.13.1 websocket-client-1.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "jupyter_client",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.67.0-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 14 kB/s \n",
            "\u001b[?25hCollecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 14.9 MB/s \n",
            "\u001b[?25hCollecting starlette==0.14.2\n",
            "  Downloading starlette-0.14.2-py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi) (3.7.4.3)\n",
            "Installing collected packages: starlette, pydantic, fastapi\n",
            "Successfully installed fastapi-0.67.0 pydantic-1.8.2 starlette-0.14.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ak2q0f4TBMA"
      },
      "source": [
        "#importing the required libraries & packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import argparse\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import regexp_tokenize\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from sklearn.utils import shuffle\n",
        "import pickle"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia9vNfhWTZ8Z"
      },
      "source": [
        "data_frame = pd.read_csv(\"/content/drive/MyDrive/airline_sentiment_analysis.csv\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "cDh_TsBITr06",
        "outputId": "0dd73384-429d-4526-dafa-e8bc50d2af71"
      },
      "source": [
        "data_frame.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                               text\n",
              "0           1  ...  @VirginAmerica plus you've added commercials t...\n",
              "1           3  ...  @VirginAmerica it's really aggressive to blast...\n",
              "2           4  ...  @VirginAmerica and it's a really big bad thing...\n",
              "3           5  ...  @VirginAmerica seriously would pay $30 a fligh...\n",
              "4           6  ...  @VirginAmerica yes, nearly every time I fly VX...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "FC8YZLt3TzG1",
        "outputId": "89496821-5f14-46ff-9271-ed58bc7f968c"
      },
      "source": [
        "data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)\n",
        "data_frame.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                               text\n",
              "0          positive  @VirginAmerica plus you've added commercials t...\n",
              "1          negative  @VirginAmerica it's really aggressive to blast...\n",
              "2          negative  @VirginAmerica and it's a really big bad thing...\n",
              "3          negative  @VirginAmerica seriously would pay $30 a fligh...\n",
              "4          positive  @VirginAmerica yes, nearly every time I fly VX..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "9IiYNfqbYGJ1",
        "outputId": "9fa17d61-4964-4555-b384-a3eb8cad2c81"
      },
      "source": [
        "data_frame.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                               text\n",
              "0          positive  @VirginAmerica plus you've added commercials t...\n",
              "1          negative  @VirginAmerica it's really aggressive to blast...\n",
              "2          negative  @VirginAmerica and it's a really big bad thing...\n",
              "3          negative  @VirginAmerica seriously would pay $30 a fligh...\n",
              "4          positive  @VirginAmerica yes, nearly every time I fly VX..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "jfCwXjchgL2d",
        "outputId": "cc564f1f-0996-4392-90c1-167dcacd4328"
      },
      "source": [
        "data_frame = shuffle(data_frame,random_state = 42)\n",
        "data_frame.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9193</th>\n",
              "      <td>negative</td>\n",
              "      <td>@USAirways They charged me for a flight they C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6112</th>\n",
              "      <td>positive</td>\n",
              "      <td>@JetBlue great flight! Great view! :-) http://...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>967</th>\n",
              "      <td>negative</td>\n",
              "      <td>@united they're not, actually. gate agent was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11279</th>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir No worries they called back 4 hrs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3061</th>\n",
              "      <td>positive</td>\n",
              "      <td>@united thank you. There was one here a few mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      airline_sentiment                                               text\n",
              "9193           negative  @USAirways They charged me for a flight they C...\n",
              "6112           positive  @JetBlue great flight! Great view! :-) http://...\n",
              "967            negative  @united they're not, actually. gate agent was ...\n",
              "11279          negative  @AmericanAir No worries they called back 4 hrs...\n",
              "3061           positive  @united thank you. There was one here a few mo..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "2hObaP05ge4s",
        "outputId": "ac3ebf86-5420-4720-e3a4-763fcf81ee14"
      },
      "source": [
        "data_frame = data_frame.reset_index()\n",
        "data_frame.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9193</td>\n",
              "      <td>negative</td>\n",
              "      <td>@USAirways They charged me for a flight they C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6112</td>\n",
              "      <td>positive</td>\n",
              "      <td>@JetBlue great flight! Great view! :-) http://...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>967</td>\n",
              "      <td>negative</td>\n",
              "      <td>@united they're not, actually. gate agent was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11279</td>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir No worries they called back 4 hrs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3061</td>\n",
              "      <td>positive</td>\n",
              "      <td>@united thank you. There was one here a few mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index airline_sentiment                                               text\n",
              "0   9193          negative  @USAirways They charged me for a flight they C...\n",
              "1   6112          positive  @JetBlue great flight! Great view! :-) http://...\n",
              "2    967          negative  @united they're not, actually. gate agent was ...\n",
              "3  11279          negative  @AmericanAir No worries they called back 4 hrs...\n",
              "4   3061          positive  @united thank you. There was one here a few mo..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "LQLZBSu_gmQe",
        "outputId": "2cb129e4-1597-4dcd-fdc2-4542373caabe"
      },
      "source": [
        "data_frame = data_frame.drop(['index'],axis = 1)\n",
        "data_frame.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>@USAirways They charged me for a flight they C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@JetBlue great flight! Great view! :-) http://...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>@united they're not, actually. gate agent was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@AmericanAir No worries they called back 4 hrs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>@united thank you. There was one here a few mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                               text\n",
              "0          negative  @USAirways They charged me for a flight they C...\n",
              "1          positive  @JetBlue great flight! Great view! :-) http://...\n",
              "2          negative  @united they're not, actually. gate agent was ...\n",
              "3          negative  @AmericanAir No worries they called back 4 hrs...\n",
              "4          positive  @united thank you. There was one here a few mo..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8J1ns5Ogu5d",
        "outputId": "930b69e8-d28f-412f-8bf4-2d1ef3e0d694"
      },
      "source": [
        "data_frame.info()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11541 entries, 0 to 11540\n",
            "Data columns (total 2 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   airline_sentiment  11541 non-null  object\n",
            " 1   text               11541 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 180.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VeolMPtg50Q",
        "outputId": "2a738df7-ff41-44e1-975b-114776cba582"
      },
      "source": [
        "data_frame['airline_sentiment'].unique()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative', 'positive'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOdwW2oChBBr",
        "outputId": "57f944d9-ec75-4635-a3c8-bc87608f40c2"
      },
      "source": [
        "data_frame['airline_sentiment'].describe()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count        11541\n",
              "unique           2\n",
              "top       negative\n",
              "freq          9178\n",
              "Name: airline_sentiment, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "sgbRB6JXhJpO",
        "outputId": "e38d268a-6568-4705-9f58-516fd0f4ce85"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_frame['airline_sentiment'].value_counts().plot.bar()\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnWfUtMyjhlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdce5231-40f0-4886-a333-301ac6948555"
      },
      "source": [
        "#repalcing the categorical values of 'airline_sentiment' to numeric values: Positive - 1, Negative - 0\n",
        "data_frame['airline_sentiment'].replace(('positive', 'negative'), (1, 0), inplace=True)\n",
        "data_frame['airline_sentiment'].value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    9178\n",
              "1    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx5SySKo_kvo"
      },
      "source": [
        "#forming the feature & label variables\n",
        "data = data_frame['text'].values.tolist()\n",
        "labels = data_frame['airline_sentiment'].values.tolist()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdA8JQ8_jhlQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e906e57-ee8f-417f-d401-c6323f77d184"
      },
      "source": [
        "#First five samples text\n",
        "data[:5]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@USAirways They charged me for a flight they Cancelled Flightled, unbelievable and unheard of',\n",
              " '@JetBlue great flight! Great view! :-) http://t.co/Yxn00pnOav',\n",
              " \"@united they're not, actually. gate agent was so rude. now standing in a line waiting for reFlight Booking Problems. missed the only flight to STI. awful.\",\n",
              " \"@AmericanAir No worries they called back 4 hrs Late Flightr while I was asleep and took an additional $200 fee. So by AA standards everything's gr8\",\n",
              " \"@united thank you. There was one here a few months ago, but none now. Weird you don't have a club in one of the busiest airports in the US.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqhUtE4f_hAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9efc10-51f6-4015-f1a2-fabda62b2722"
      },
      "source": [
        "#first 5 samples label\n",
        "labels[:5]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 0, 0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pduz91hcjhlb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ef1651-23cf-4d04-a381-3d223004a1d2"
      },
      "source": [
        "#splitting the data into 80 and 20 split\n",
        "train_X, test_X, y_train, y_test = train_test_split(data, labels, test_size=0.2, \n",
        "                                                    random_state=42, shuffle=True)\n",
        "\n",
        "print(f'Number of training examples: {len(train_X)}')\n",
        "print(f'Number of testing examples: {len(test_X)}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 9232\n",
            "Number of testing examples: 2309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88pSFeEzAgH9"
      },
      "source": [
        "**Text preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGX16pKBjhlm"
      },
      "source": [
        "# Here is a default pattern for tokenization\n",
        "default_pattern =  r\"\"\"(?x)                  \n",
        "                        (?:[A-Z]\\.)+          \n",
        "                        |\\$?\\d+(?:\\.\\d+)?%?    \n",
        "                        |\\w+(?:[-']\\w+)*      \n",
        "                        |\\.\\.\\.               \n",
        "                        |(?:[.,;\"'?():-_`])    \n",
        "                    \"\"\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkncRcuijhlx"
      },
      "source": [
        "#funtion for tokenizing the data\n",
        "def tokenize(text, pattern = default_pattern):\n",
        "  text = text.lower()\n",
        "  return regexp_tokenize(text, pattern)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCTB0sWwjhl7"
      },
      "source": [
        "# Tokenize training text into tokens\n",
        "tokenized_text = []\n",
        "for i in range(0, len(train_X)):\n",
        "    tokenized_text.append(tokenize(train_X[i]))\n",
        "\n",
        "X_train = tokenized_text\n",
        "\n",
        "# Tokenize testing text into tokens\n",
        "tokenized_text = []\n",
        "for i in range(0, len(test_X)):\n",
        "    tokenized_text.append(tokenize(test_X[i]))\n",
        "\n",
        "X_test = tokenized_text"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7yG2O98jhmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3936f172-03e6-4087-fdd1-201a13a085c3"
      },
      "source": [
        "#tokenized train & test data\n",
        "print(X_train[0], X_train[1])\n",
        "print(X_test[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['@', 'usairways', 'been', 'on', 'hold', '2.5', 'hours', 'now', 'system', 'hung', 'up', 'on', 'me', 'twice', 'after', 'an', 'hour', 'holding', '.', ':', '(', 'trying', '2', 'correct', 'online', 'flight', 'booking', 'problems', 'error', '.', 'unhappy'] ['@', 'americanair', 'what', 'is', 'that', '?', 'why', 'even', 'bother', 'catering', 'dog', 'food', 'that', 'no', 'one', 'will', 'eat', '?', 'http', ':', 't', '.', 'co', 'ifespcbztm']\n",
            "['@', 'americanair', 'can', 'you', 'tell', 'me', 'why', 'all', 'flights', 'from', 'xna', '2', 'dfw', 'are', 'cancelled', 'flightled', 'for', 'tomorrow', 'morning', 'already', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFyEv5ERPuB3"
      },
      "source": [
        "#building dictionary\n",
        "def createDictionary(data):\n",
        "  \"\"\" Function: To create a dictionary of tokens from the data\n",
        "  Arguments: data in the type - list\n",
        "  Returns: Sorted dictionary of the tokens and their count in the data \"\"\"\n",
        "\n",
        "  dictionary = dict()\n",
        "  for sample in  data:\n",
        "    for token in sample:\n",
        "      dictionary[token] = dictionary.get(token, 0) + 1\n",
        "  #sorting the dictionary based on the values\n",
        "  sorted_dict = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
        "  return dict(sorted_dict)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgbUxDeAU4oR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669c0c88-8d55-4dc2-d433-0775fa2ee192"
      },
      "source": [
        "bog = createDictionary(X_train)\n",
        "#top 10 items in the dictionary\n",
        "print(\"Top 10 tokens in the training dictionary:\\n\")\n",
        "list(bog.items())[:10]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 tokens in the training dictionary:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', 10616),\n",
              " ('@', 10369),\n",
              " ('to', 5633),\n",
              " ('the', 4027),\n",
              " ('i', 3425),\n",
              " ('a', 2967),\n",
              " (',', 2837),\n",
              " ('united', 2734),\n",
              " ('you', 2721),\n",
              " ('for', 2719)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auz1uD0IjhmI",
        "scrolled": false
      },
      "source": [
        "#Navie Bayes Classifier \n",
        "class NBClassifier:\n",
        "\n",
        "    def __init__(self, X_train, y_train, size):\n",
        "      # tz_NY = pytz.timezone('America/New_York') \n",
        "      # print(\"Model Start Time:\", datetime.now(tz_NY).strftime(\"%H:%M:%S\"))\n",
        "      self.X_train = X_train\n",
        "      self.y_train = y_train\n",
        "      self.size = size\n",
        "\n",
        "    def createDictionary(self):\n",
        "      \"\"\" Function: To create a dictionary of tokens from the data\n",
        "      Arguments: data in the type - list\n",
        "      Returns: Sorted dictionary of the tokens and their count in the data \"\"\"\n",
        "      dictionary = dict()\n",
        "      for sample in  X_train:\n",
        "        for token in sample:\n",
        "          dictionary[token] = dictionary.get(token, 0) + 1\n",
        "      #sorting the dictionary based on the values\n",
        "      sorted_dict = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
        "      return dict(sorted_dict)\n",
        "    \n",
        "    def fit(self):\n",
        "      \"\"\" Function: To compute the count of words in training data dictionary\n",
        "        Arguments: Trianing data & Size of dictionary\n",
        "        Returns: dictionary of tokens with their class wise probabilities \"\"\"\n",
        "      \n",
        "      X_train_dict = self.createDictionary()\n",
        "      if self.size == 'full':\n",
        "        self.words_list = list(X_train_dict.keys())\n",
        "        self.words_count = dict.fromkeys(self.words_list, None)\n",
        "      else:\n",
        "        self.words_list = list(X_train_dict.keys())[:int(self.size)]\n",
        "        self.words_count = dict.fromkeys(self.words_list, None)\n",
        "            \n",
        "      #DataFrame of training data\n",
        "      train = pd.DataFrame(columns = ['X_train', 'y_train'])\n",
        "      train['X_train'] = X_train\n",
        "      train['y_train'] = y_train\n",
        "\n",
        "      train_0 = train.copy()[train['y_train'] == 0]\n",
        "      train_1 = train.copy()[train['y_train'] == 1]\n",
        "      train_2 = train.copy()[train['y_train'] == 2]\n",
        "\n",
        "      #computing the prior of each class\n",
        "      Pr0 = train_0.shape[0]/train.shape[0]\n",
        "      Pr1 = train_1.shape[0]/train.shape[0]\n",
        "      Pr2 = train_2.shape[0]/train.shape[0]\n",
        "      \n",
        "      self.Prior = np.array([Pr0, Pr1, Pr2])\n",
        "        \n",
        "      #converting list of lists into a list\n",
        "      def flatList(listOfList):\n",
        "        flatten = []\n",
        "        for elem in listOfList:\n",
        "          flatten.extend(elem)\n",
        "        return flatten\n",
        "  \n",
        "      #Creating the data list for each class - tokens of each class\n",
        "      X_train_0 = flatList(train[train['y_train'] == 0]['X_train'].tolist())\n",
        "      X_train_1 = flatList(train[train['y_train'] == 1]['X_train'].tolist())\n",
        "      X_train_2 = flatList(train[train['y_train'] == 2]['X_train'].tolist())\n",
        "    \n",
        "      self.X_train_len = np.array([len(X_train_0), len(X_train_1), len(X_train_2)])\n",
        "\n",
        "      for token in self.words_list:\n",
        "        #list to store three word counts of a token\n",
        "        res = []\n",
        "\n",
        "        #inserting count of token in class 0: Neutral\n",
        "        res.insert(0, X_train_0.count(token))\n",
        "\n",
        "        #inserting count of token in class 1: Positive\n",
        "        res.insert(1, X_train_1.count(token))\n",
        "\n",
        "          #inserting count of token in class 2: Negative\n",
        "        res.insert(2, X_train_2.count(token))\n",
        "\n",
        "        #assigning the count list to its token in the dictionary \n",
        "        self.words_count[token] = res\n",
        "      return self\n",
        "\n",
        "    def predict(self, X_test):\n",
        "      \"\"\" Function: Predicts the label of the data\n",
        "        Arguments: self and the test data\n",
        "        Returns: List of predicted labels for the test data \"\"\"     \n",
        "      pred = []\n",
        "      for sample in X_test:\n",
        "        mul = np.array([1,1,1])\n",
        "        for tokens in sample:\n",
        "          vocab_count = len(self.words_list)\n",
        "          if tokens in self.words_list:\n",
        "            prob = ((np.array(self.words_count[tokens])+1) / (self.X_train_len + vocab_count))\n",
        "          #except:\n",
        "            #prob = ((np.array([0,0,0])+1) / (self.X_train_len + vocab_count))\n",
        "          mul = mul * prob\n",
        "        val = mul * self.Prior\n",
        "        pred.append(np.argmax(val))\n",
        "      tz_NY = pytz.timezone('America/New_York') \n",
        "      print(\"Model End Time:\", datetime.now(tz_NY).strftime(\"%H:%M:%S\"))\n",
        "      return pred\n",
        "    \n",
        "    def score(self, pred, labels):\n",
        "      \"\"\" Function: To compute the perfoemance of the model\n",
        "        Arguments: self, predicted labels and actual labels of the test data\n",
        "        Returns: Number of lables correctly predicted and the accuracy of the model \"\"\"\n",
        "      correct = (np.array(pred) == np.array(labels)).sum()\n",
        "      accuracy = correct/len(pred)\n",
        "      return correct, accuracy"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIOaYPc_jhmW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "826fe459-af9b-4b72-a5e2-14819bf245d9"
      },
      "source": [
        "#string of punctiations\n",
        "string.punctuation"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45mxN-D2jhma",
        "scrolled": true
      },
      "source": [
        "#Removing the punctuation\n",
        "'''Function: Removes the punctuation from the tokens\n",
        "   Arguments: list of text data samples\n",
        "   Returns: list of tokens of each sample without punctuation '''\n",
        "def removePunctuation(data):\n",
        "    update = []\n",
        "    for sample in data:\n",
        "        #removing punctuation from the tokens\n",
        "        re_punct = [''.join(char for char in word if char not in string.punctuation) for word in sample]\n",
        "        #removes the empty strings\n",
        "        re_punct = [word for word in re_punct if word]\n",
        "       \n",
        "        update.append(re_punct)\n",
        "    return update"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXl-ISTr0H1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b19bb68-a7d4-4540-f7eb-de04e5c4bc85"
      },
      "source": [
        "#Removing punctuation from training data text tokens  \n",
        "X_train = removePunctuation(X_train)\n",
        "\n",
        "#Removing punctuation from testing data text tokens\n",
        "X_test = removePunctuation(X_test)\n",
        "\n",
        "#train & test data after removing punctuation\n",
        "print(X_train[0])\n",
        "print(X_test[0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['usairways', 'been', 'on', 'hold', '25', 'hours', 'now', 'system', 'hung', 'up', 'on', 'me', 'twice', 'after', 'an', 'hour', 'holding', 'trying', '2', 'correct', 'online', 'flight', 'booking', 'problems', 'error', 'unhappy']\n",
            "['americanair', 'can', 'you', 'tell', 'me', 'why', 'all', 'flights', 'from', 'xna', '2', 'dfw', 'are', 'cancelled', 'flightled', 'for', 'tomorrow', 'morning', 'already']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmTW-U4iFHFQ"
      },
      "source": [
        "'''Function: Removes the stopwords from the tokens'''\n",
        "def removeStopWords(data):\n",
        "    update = []\n",
        "    stopwords = ['the', 'at','i', 'of', 'us', 'have', 'a', 'you','ours', 'themselves', \n",
        "                 'that', 'this', 'be', 'is', 'for']\n",
        "    for sample in data:\n",
        "        #removing stopwords from tokenized data\n",
        "        re_stop = [word for word in sample if word not in stopwords]\n",
        "        \n",
        "        update.append(re_stop)\n",
        "    return update"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZZzVzpmjhmd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38bcdda2-efeb-45f2-bf5f-6348d626ee3a"
      },
      "source": [
        "#Removing stopwords from training data text tokens  \n",
        "X_train = removeStopWords(X_train)\n",
        "\n",
        "#Removing stopwords from testing data text tokens\n",
        "X_test = removeStopWords(X_test)\n",
        "\n",
        "#train & test data after removing stopwords\n",
        "print(X_train[0])\n",
        "print(X_test[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['usairways', 'been', 'on', 'hold', '25', 'hours', 'now', 'system', 'hung', 'up', 'on', 'me', 'twice', 'after', 'an', 'hour', 'holding', 'trying', '2', 'correct', 'online', 'flight', 'booking', 'problems', 'error', 'unhappy']\n",
            "['americanair', 'can', 'tell', 'me', 'why', 'all', 'flights', 'from', 'xna', '2', 'dfw', 'are', 'cancelled', 'flightled', 'tomorrow', 'morning', 'already']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKtz7kfP1R2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b89aeb-92b2-40d9-dbb4-a27891eca78e"
      },
      "source": [
        "#total tokens in training dictionary\n",
        "print('Total tokens in the dictionary:', len(bog))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total tokens in the dictionary: 11400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0TqGF2sjhmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c11451c-4272-4298-c831-7b578c658dc6"
      },
      "source": [
        "#training the classifier     \n",
        "nb = NBClassifier(X_train, y_train, '5000')  \n",
        "nb.fit()\n",
        "\n",
        "#predicting the labels for test samples\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "#Checking\n",
        "print(\"NBClassifier Model miss any prediction???\", len(X_test) != len(y_pred))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model End Time: 08:20:09\n",
            "NBClassifier Model miss any prediction??? False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLDjMGp0jhmR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a01cdee-b53f-4401-d736-9dcfadeeca1a"
      },
      "source": [
        "#Performance of the classifier\n",
        "cor1, acc1 = nb.score(y_pred, y_test)\n",
        "print(\"Count of Correct Predictions:\", cor1)\n",
        "print(\"Accuracy of the model: %i / %i = %.4f \" %(cor1, len(y_pred), acc1))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of Correct Predictions: 2112\n",
            "Accuracy of the model: 2112 / 2309 = 0.9147 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLCkKM-KCA8B"
      },
      "source": [
        "**Developing API server using Fast API and Swagger UI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_jL2xEqzBqH"
      },
      "source": [
        "#Saving the model\n",
        "Pkl_Filename = \"Naive_Bayes.pkl\"  \n",
        "\n",
        "with open(Pkl_Filename, 'wb') as file:  \n",
        "    pickle.dump(nb, file)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyCYr5OA3OOX"
      },
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class Text(BaseModel):\n",
        "    english_text:list\n",
        "    \n",
        "    class Config:\n",
        "        schema_extra = {\n",
        "            \"example\": {\n",
        "                \"english_text\": [\"This is the worst flight for travelling\"]\n",
        "            }\n",
        "        }"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25jZXDp4zCvc"
      },
      "source": [
        "from fastapi import FastAPI\n",
        "import pickle\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_model():\n",
        "    global model\n",
        "    model = pickle.load(open(\"Naive_Bayes.pkl\", \"rb\"))\n",
        "\n",
        "@app.get('/')\n",
        "def index():\n",
        "    return {'message': 'This is the homepage of the API '}\n",
        "\n",
        "@app.post('/predict')\n",
        "def get_sentiment(data:Text):\n",
        "    received = data.dict()\n",
        "    text = received['english_text']\n",
        "    tokenized_text = []\n",
        "    for i in range(0, len(text)):\n",
        "        tokenized_text.append(tokenize(text[i]))\n",
        "    text = tokenized_text\n",
        "    text = removePunctuation(text)\n",
        "    text = removeStopWords(text)\n",
        "    \n",
        "    pred_category = model.predict(text)\n",
        "    if pred_category[0] == 1:\n",
        "      pred = \"positive\"\n",
        "    else:\n",
        "        pred = \"negative\"\n",
        "        \n",
        "    return {'prediction': pred}"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K10DRvhLzE0d"
      },
      "source": [
        "from colabcode import ColabCode\n",
        "server = ColabCode(port=10000, code=False)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7RMsUchzHEz",
        "outputId": "056853db-ba1c-4b5d-b66c-8262b9828111"
      },
      "source": [
        "server.run_app(app=app)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [62]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:10000 (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://c11fc88c73c0.ngrok.io\" -> \"http://localhost:10000\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qbgE5ckLU53"
      },
      "source": [
        "# !pip freeze > requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}